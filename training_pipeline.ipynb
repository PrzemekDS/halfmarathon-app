{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719f24b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Wczytywanie danych...\n",
      "üîç STRUKTURA DANYCH 2023:\n",
      "Kolumny: ['Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo']\n",
      "Pierwsze 5 wierszy:\n",
      "  Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo\n",
      "0  1.0;1787;TOMASZ;GRYCKO;;POL;UKS BLIZA W≈ÅADYS≈ÅA...                                                                                                                                                                                                                                                                             \n",
      "1  2.0;3;ARKADIUSZ;GARDZIELEWSKI;WROC≈ÅAW;POL;ARKA...                                                                                                                                                                                                                                                                             \n",
      "2  3.0;3832;KRZYSZTOF;HADAS;POZNA≈É;POL;;M;3;M20;1...                                                                                                                                                                                                                                                                             \n",
      "3  4.0;416;DAMIAN;DYDUCH;KƒòPNO;POL;AZS POLITECHNI...                                                                                                                                                                                                                                                                             \n",
      "4  5.0;8476;KAMIL;MA≈ÉKOWSKI;MIRK√ìW;POL;PARKRUN WR...                                                                                                                                                                                                                                                                             \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8950 entries, 0 to 8949\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                                                                                                                           Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                                                                                                                           --------------  ----- \n",
      " 0   Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo  8950 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 70.1+ KB\n",
      "None\n",
      "\n",
      "üîç STRUKTURA DANYCH 2024:\n",
      "Kolumny: ['Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo']\n",
      "Pierwsze 5 wierszy:\n",
      "  Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo\n",
      "0  1.0;596;NIKODEM;DWORCZAK;KO≈öCIAN;POL;;M;1;M20;...                                                                                                                                                                                                                                                                             \n",
      "1  2.0;616;MATEUSZ;KACZOR;RADOM;POL;RLTL OPTIMA R...                                                                                                                                                                                                                                                                             \n",
      "2  3.0;154;PATRYK;KOZ≈ÅOWSKI;RADOM;POL;RLTL-ZTE-RA...                                                                                                                                                                                                                                                                             \n",
      "3  4.0;591;DARIUSZ;BORATY≈ÉSKI;WROC≈ÅAW;POL;WOSIEK ...                                                                                                                                                                                                                                                                             \n",
      "4  5.0;521;SZYMON;DORO≈ªY≈ÉSKI;LUBON;POL;SZYMI TEAM...                                                                                                                                                                                                                                                                             \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13007 entries, 0 to 13006\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                                                                                                                           Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                                                                                                                           --------------  ----- \n",
      " 0   Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo  13007 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 101.7+ KB\n",
      "None\n",
      "‚úÖ Kolumny sƒÖ identyczne - mo≈ºna ≈ÇƒÖczyƒá\n",
      "\n",
      "üìä Po≈ÇƒÖczone dane: (21957, 1)\n",
      "\n",
      "üéØ ANALIZA KOLUMN:\n",
      "\n",
      "Miejsce;Numer startowy;Imiƒô;Nazwisko;Miasto;Kraj;Dru≈ºyna;P≈Çeƒá;P≈Çeƒá Miejsce;Kategoria wiekowa;Kategoria wiekowa Miejsce;Rocznik;5 km Czas;5 km Miejsce Open;5 km Tempo;10 km Czas;10 km Miejsce Open;10 km Tempo;15 km Czas;15 km Miejsce Open;15 km Tempo;20 km Czas;20 km Miejsce Open;20 km Tempo;Tempo Stabilno≈õƒá;Czas;Tempo:\n",
      "  Typ: object\n",
      "  Unikalne warto≈õci: 21957\n",
      "  Braki: 0\n"
     ]
    }
   ],
   "source": [
    "# training_pipeline_debug.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Za≈Çaduj zmienne ≈õrodowiskowe\n",
    "load_dotenv()\n",
    "\n",
    "# Po≈ÇƒÖczenie z DigitalOcean Spaces\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client('s3',\n",
    "                   region_name=os.getenv('DO_SPACES_REGION'),\n",
    "                   endpoint_url=os.getenv('DO_SPACES_ENDPOINT'),\n",
    "                   aws_access_key_id=os.getenv('DO_SPACES_KEY'),\n",
    "                   aws_secret_access_key=os.getenv('DO_SPACES_SECRET'))\n",
    "\n",
    "# Funkcja do wczytywania CSV z Spaces\n",
    "def load_csv_from_spaces(filename):\n",
    "    response = s3.get_object(Bucket=os.getenv('DO_SPACES_BUCKET'), Key=filename)\n",
    "    return pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "print(\"üì• Wczytywanie danych...\")\n",
    "# Wczytaj dane z 2023 i 2024\n",
    "df_2023 = load_csv_from_spaces('halfmarathon_wroclaw_2023__final.csv')\n",
    "df_2024 = load_csv_from_spaces('halfmarathon_wroclaw_2024__final.csv')\n",
    "\n",
    "print(\"üîç STRUKTURA DANYCH 2023:\")\n",
    "print(\"Kolumny:\", df_2023.columns.tolist())\n",
    "print(\"Pierwsze 5 wierszy:\")\n",
    "print(df_2023.head())\n",
    "print(\"\\nInfo:\")\n",
    "print(df_2023.info())\n",
    "\n",
    "print(\"\\nüîç STRUKTURA DANYCH 2024:\")\n",
    "print(\"Kolumny:\", df_2024.columns.tolist())\n",
    "print(\"Pierwsze 5 wierszy:\")\n",
    "print(df_2024.head())\n",
    "print(\"\\nInfo:\")\n",
    "print(df_2024.info())\n",
    "\n",
    "# Sprawd≈∫ czy kolumny sƒÖ takie same\n",
    "if df_2023.columns.tolist() == df_2024.columns.tolist():\n",
    "    print(\"‚úÖ Kolumny sƒÖ identyczne - mo≈ºna ≈ÇƒÖczyƒá\")\n",
    "else:\n",
    "    print(\"‚ùå Kolumny sƒÖ r√≥≈ºne - trzeba dostosowaƒá\")\n",
    "\n",
    "# Po≈ÇƒÖcz dane je≈õli kolumny pasujƒÖ\n",
    "df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "print(f\"\\nüìä Po≈ÇƒÖczone dane: {df.shape}\")\n",
    "\n",
    "# POKA≈ª WSZYSTKIE KOLUMNY i ich unikalne warto≈õci\n",
    "print(\"\\nüéØ ANALIZA KOLUMN:\")\n",
    "for col in df.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Typ: {df[col].dtype}\")\n",
    "    print(f\"  Unikalne warto≈õci: {df[col].nunique()}\")\n",
    "    if df[col].nunique() < 10:\n",
    "        print(f\"  Warto≈õci: {df[col].unique()}\")\n",
    "    print(f\"  Braki: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb8879c-18f2-413f-a822-302ea39f7ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Wczytywanie i przetwarzanie danych...\n",
      "üîç STRUKTURA DANYCH 2023 PO ROZDZIELENIU:\n",
      "Kolumny: ['1.0', '1787', 'TOMASZ', 'GRYCKO', '', 'POL', 'UKS BLIZA W≈ÅADYS≈ÅAWOWO', 'M', '1', 'M30', '1', '1992.0', '00:14:37', '1.0', '2.9233333333333333', '00:29:15', '1.0', '2.9266666666666667', '00:44:47', '1.0', '3.106666666666667', '01:01:43', '1.0', '3.3866666666666663', '0.031399999999999956', '01:04:59', '3.0805088093545074']\n",
      "Wymiar: (8949, 27)\n",
      "\n",
      "Pierwsze 3 wiersze:\n",
      "0  1.0  1787     TOMASZ         GRYCKO           POL  \\\n",
      "1  2.0     3  ARKADIUSZ  GARDZIELEWSKI  WROC≈ÅAW  POL   \n",
      "2  3.0  3832  KRZYSZTOF          HADAS   POZNA≈É  POL   \n",
      "3  4.0   416     DAMIAN         DYDUCH    KƒòPNO  POL   \n",
      "\n",
      "0     UKS BLIZA W≈ÅADYS≈ÅAWOWO  M  1  M30  ...  2.9266666666666667  00:44:47  \\\n",
      "1  ARKADIUSZGARDZIELEWSKI.PL  M  2  M30  ...  2.9833333333333334  00:45:26   \n",
      "2                             M  3  M20  ...  3.1233333333333335  00:47:34   \n",
      "3   AZS POLITECHNIKA OPOLSKA  M  4  M30  ...  3.1966666666666668  00:48:49   \n",
      "\n",
      "0  1.0   3.106666666666667  01:01:43  1.0  3.3866666666666663  \\\n",
      "1  2.0   3.143333333333333  01:03:08  2.0                3.54   \n",
      "2  3.0  3.2366666666666664  01:05:09  3.0  3.5166666666666666   \n",
      "3  5.0                3.33  01:06:54  4.0  3.6166666666666667   \n",
      "\n",
      "0  0.031399999999999956  01:04:59  3.0805088093545074  \n",
      "1   0.03800000000000006  01:06:23  3.1468752468989494  \n",
      "2  0.024066666666666733  01:08:24   3.242474520028443  \n",
      "3  0.025466666666666783  01:10:16  3.3309631034210323  \n",
      "\n",
      "[3 rows x 27 columns]\n",
      "\n",
      "üîç STRUKTURA DANYCH 2024 PO ROZDZIELENIU:\n",
      "Kolumny: ['1.0', '596', 'NIKODEM', 'DWORCZAK', 'KO≈öCIAN', 'POL', '', 'M', '1', 'M20', '1', '1998.0', '00:15:06', '3.0', '3.02', '00:29:42', '3.0', '2.92', '00:45:07', '2.0', '3.0833333333333335', '01:00:33', '1.0', '3.0866666666666664', '0.007266666666666816', '01:04:03', '3.036264517658213']\n",
      "Wymiar: (13006, 27)\n",
      "\n",
      "Pierwsze 3 wiersze:\n",
      "0  1.0  596  NIKODEM    DWORCZAK  KO≈öCIAN  POL                               \\\n",
      "1  2.0  616  MATEUSZ      KACZOR    RADOM  POL            RLTL OPTIMA RADOM   \n",
      "2  3.0  154   PATRYK   KOZ≈ÅOWSKI    RADOM  POL               RLTL-ZTE-RADOM   \n",
      "3  4.0  591  DARIUSZ  BORATY≈ÉSKI  WROC≈ÅAW  POL  WOSIEK TEAM AZS AWF WROC≈ÅAW   \n",
      "\n",
      "0  M  1  M20  ...  2.92  00:45:07  2.0  3.0833333333333335  01:00:33  1.0  \\\n",
      "1  M  2  M20  ...  2.92  00:45:07  3.0  3.0833333333333335  01:00:38  2.0   \n",
      "2  M  3  M20  ...  2.92  00:45:07  1.0  3.0833333333333335  01:00:59  3.0   \n",
      "3  M  4  M20  ...  3.11  00:47:48  4.0  3.2933333333333334  01:05:40  4.0   \n",
      "\n",
      "0  3.0866666666666664  0.007266666666666816  01:04:03   3.036264517658213  \n",
      "1   3.103333333333333  0.008266666666666768  01:04:24  3.0528561270443233  \n",
      "2  3.1733333333333333   0.01246666666666684  01:04:40   3.065497353243265  \n",
      "3  3.5733333333333333  0.028666666666666712  01:09:44    3.30568065102315  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_2024\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Po≈ÇƒÖcz dane\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_2023, df_2024], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Po≈ÇƒÖczone dane: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# ANALIZA KOLUMN - kt√≥re nas interesujƒÖ\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:676\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    674\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    675\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 676\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    678\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    680\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    681\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    682\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3875\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3872\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3875\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# training_pipeline_fixed.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Za≈Çaduj zmienne ≈õrodowiskowe\n",
    "load_dotenv()\n",
    "\n",
    "# Po≈ÇƒÖczenie z DigitalOcean Spaces\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client('s3',\n",
    "                   region_name=os.getenv('DO_SPACES_REGION'),\n",
    "                   endpoint_url=os.getenv('DO_SPACES_ENDPOINT'),\n",
    "                   aws_access_key_id=os.getenv('DO_SPACES_KEY'),\n",
    "                   aws_secret_access_key=os.getenv('DO_SPACES_SECRET'))\n",
    "\n",
    "# Funkcja do wczytywania i rozdzielania CSV\n",
    "def load_and_split_csv_from_spaces(filename):\n",
    "    response = s3.get_object(Bucket=os.getenv('DO_SPACES_BUCKET'), Key=filename)\n",
    "    # Wczytaj jako pojedynczƒÖ kolumnƒô\n",
    "    df_temp = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "    \n",
    "    # Rozdziel kolumny wed≈Çug ≈õrednika\n",
    "    df_split = df_temp.iloc[:, 0].str.split(';', expand=True)\n",
    "    \n",
    "    # Ustaw nazwy kolumn z pierwszego wiersza\n",
    "    df_split.columns = df_split.iloc[0]\n",
    "    df_split = df_split[1:]  # Usu≈Ñ pierwszy wiersz (nag≈Ç√≥wki)\n",
    "    \n",
    "    return df_split\n",
    "\n",
    "print(\"üì• Wczytywanie i przetwarzanie danych...\")\n",
    "# Wczytaj i rozdziel dane\n",
    "df_2023 = load_and_split_csv_from_spaces('halfmarathon_wroclaw_2023__final.csv')\n",
    "df_2024 = load_and_split_csv_from_spaces('halfmarathon_wroclaw_2024__final.csv')\n",
    "\n",
    "print(\"üîç STRUKTURA DANYCH 2023 PO ROZDZIELENIU:\")\n",
    "print(\"Kolumny:\", df_2023.columns.tolist())\n",
    "print(\"Wymiar:\", df_2023.shape)\n",
    "print(\"\\nPierwsze 3 wiersze:\")\n",
    "print(df_2023.head(3))\n",
    "\n",
    "print(\"\\nüîç STRUKTURA DANYCH 2024 PO ROZDZIELENIU:\")\n",
    "print(\"Kolumny:\", df_2024.columns.tolist())\n",
    "print(\"Wymiar:\", df_2024.shape)\n",
    "print(\"\\nPierwsze 3 wiersze:\")\n",
    "print(df_2024.head(3))\n",
    "\n",
    "# Po≈ÇƒÖcz dane\n",
    "df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "print(f\"\\nüìä Po≈ÇƒÖczone dane: {df.shape}\")\n",
    "\n",
    "# ANALIZA KOLUMN - kt√≥re nas interesujƒÖ\n",
    "print(\"\\nüéØ KOLUMNY DO MODELU:\")\n",
    "interesting_cols = ['P≈Çeƒá', 'Rocznik', '5 km Czas', '5 km Tempo', 'Czas', 'Tempo']\n",
    "for col in interesting_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Przyk≈Çadowe warto≈õci: {df[col].head(3).tolist()}\")\n",
    "        print(f\"  Unikalne: {df[col].nunique()}\")\n",
    "        print(f\"  Braki: {df[col].isnull().sum()}\")\n",
    "\n",
    "# Przygotowanie danych do modelu\n",
    "print(\"\\nüîß Przygotowanie danych do trenowania...\")\n",
    "\n",
    "# Konwersja typ√≥w danych\n",
    "df['Rocznik'] = pd.to_numeric(df['Rocznik'], errors='coerce')\n",
    "df['Czas'] = df['Czas'].astype(str)\n",
    "\n",
    "# Funkcja do konwersji czasu HH:MM:SS na sekundy\n",
    "def time_to_seconds(time_str):\n",
    "    try:\n",
    "        if pd.isna(time_str):\n",
    "            return None\n",
    "        parts = str(time_str).split(':')\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            return int(parts[0]) * 60 + int(parts[1])\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Konwersja czas√≥w na sekundy\n",
    "df['half_marathon_seconds'] = df['Czas'].apply(time_to_seconds)\n",
    "df['pace_5km_seconds'] = df['5 km Tempo'].apply(time_to_seconds)\n",
    "\n",
    "# P≈Çeƒá na liczby (M -> 1, K -> 0)\n",
    "df['sex_numeric'] = df['P≈Çeƒá'].map({'M': 1, 'K': 0})\n",
    "\n",
    "# Wiek z rocznika\n",
    "current_year = 2024\n",
    "df['age'] = current_year - df['Rocznik']\n",
    "\n",
    "# Przygotowanie cech i targetu\n",
    "features = df[['sex_numeric', 'age', 'pace_5km_seconds']].dropna()\n",
    "target = df.loc[features.index, 'half_marathon_seconds']\n",
    "\n",
    "print(f\"\\nüìä Dane do trenowania:\")\n",
    "print(f\"Cechy: {features.shape}\")\n",
    "print(f\"Target: {target.shape}\")\n",
    "\n",
    "if len(features) > 0:\n",
    "    # Podzia≈Ç na train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "    # Trenowanie modelu\n",
    "    print(\"\\nü§ñ Trenowanie modelu...\")\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Ewaluacja\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nüìä Wyniki modelu:\")\n",
    "    print(f\"MAE: {mae:.2f} sekund ({mae/60:.1f} minut)\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mse):.2f} sekund\")\n",
    "\n",
    "    # Zapis modelu do DigitalOcean Spaces\n",
    "    print(\"\\nüíæ Zapis modelu...\")\n",
    "    model_bytes = io.BytesIO()\n",
    "    joblib.dump(model, model_bytes)\n",
    "    model_bytes.seek(0)\n",
    "\n",
    "    s3.upload_fileobj(model_bytes, \n",
    "                      os.getenv('DO_SPACES_BUCKET'), \n",
    "                      'trained_model.pkl')\n",
    "\n",
    "    print(\"‚úÖ Model zapisany w DO Spaces!\")\n",
    "\n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(f\"\\nüéØ Wa≈ºno≈õƒá cech:\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    print(\"\\nüéâ Pipeline treningowy zako≈Ñczony!\")\n",
    "else:\n",
    "    print(\"‚ùå Brak danych do trenowania!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647a7c98-c980-4f0d-992e-c7e7c8a5668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Przetwarzanie danych 2023...\n",
      "üìä 2023 - znalezione kolumny:\n",
      "\n",
      "üì• Przetwarzanie danych 2024...\n",
      "üìä 2024 - znalezione kolumny:\n",
      "\n",
      "üìä Po≈ÇƒÖczone dane: (21955, 1)\n",
      "\n",
      "üîç PRZYK≈ÅADOWE DANE:\n",
      "   Year\n",
      "0  2023\n",
      "1  2023\n",
      "2  2023\n",
      "3  2023\n",
      "4  2023\n",
      "\n",
      "üîß Przygotowanie danych do trenowania...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'P≈Çeƒá'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'P≈Çeƒá'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Konwersja danych\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_numeric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP≈Çeƒá\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM \u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK \u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m})\n\u001b[0;32m    115\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRocznik_num\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRocznik\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    116\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalf_marathon_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCzas\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(time_to_seconds)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'P≈Çeƒá'"
     ]
    }
   ],
   "source": [
    "# training_pipeline_fixed_v3.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Za≈Çaduj zmienne ≈õrodowiskowe\n",
    "load_dotenv()\n",
    "\n",
    "# Po≈ÇƒÖczenie z DigitalOcean Spaces\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client('s3',\n",
    "                   region_name=os.getenv('DO_SPACES_REGION'),\n",
    "                   endpoint_url=os.getenv('DO_SPACES_ENDPOINT'),\n",
    "                   aws_access_key_id=os.getenv('DO_SPACES_KEY'),\n",
    "                   aws_secret_access_key=os.getenv('DO_SPACES_SECRET'))\n",
    "\n",
    "# Funkcja do wczytywania i przetwarzania ka≈ºdego roku osobno\n",
    "def process_year_data(filename, year):\n",
    "    response = s3.get_object(Bucket=os.getenv('DO_SPACES_BUCKET'), Key=filename)\n",
    "    df_temp = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "    \n",
    "    # Rozdziel kolumny wed≈Çug ≈õrednika\n",
    "    df_split = df_temp.iloc[:, 0].str.split(';', expand=True)\n",
    "    \n",
    "    # Ustaw nazwy kolumn z pierwszego wiersza\n",
    "    original_columns = df_split.iloc[0].tolist()\n",
    "    df_split.columns = original_columns\n",
    "    df_split = df_split[1:]  # Usu≈Ñ nag≈Ç√≥wki\n",
    "    \n",
    "    # Mapowanie kolumn na podstawie analizy struktury\n",
    "    column_mapping = {\n",
    "        'P≈Çeƒá': 'P≈Çeƒá',\n",
    "        'Rocznik': 'Rocznik', \n",
    "        '5 km Tempo': '5 km Tempo',\n",
    "        'Czas': 'Czas'\n",
    "    }\n",
    "    \n",
    "    # Znajd≈∫ w≈Ça≈õciwe kolumny\n",
    "    actual_mapping = {}\n",
    "    for target_col in column_mapping.keys():\n",
    "        for actual_col in df_split.columns:\n",
    "            if target_col in actual_col:\n",
    "                actual_mapping[target_col] = actual_col\n",
    "                break\n",
    "    \n",
    "    print(f\"üìä {year} - znalezione kolumny:\")\n",
    "    for target, actual in actual_mapping.items():\n",
    "        print(f\"  {target}: {actual}\")\n",
    "    \n",
    "    # Wybierz tylko potrzebne kolumny\n",
    "    selected_data = df_split[list(actual_mapping.values())].copy()\n",
    "    selected_data.columns = list(actual_mapping.keys())  # Ustandaryzuj nazwy\n",
    "    selected_data['Year'] = year\n",
    "    \n",
    "    return selected_data\n",
    "\n",
    "print(\"üì• Przetwarzanie danych 2023...\")\n",
    "df_2023 = process_year_data('halfmarathon_wroclaw_2023__final.csv', 2023)\n",
    "\n",
    "print(\"\\nüì• Przetwarzanie danych 2024...\")\n",
    "df_2024 = process_year_data('halfmarathon_wroclaw_2024__final.csv', 2024)\n",
    "\n",
    "# Po≈ÇƒÖcz dane\n",
    "df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "print(f\"\\nüìä Po≈ÇƒÖczone dane: {df.shape}\")\n",
    "\n",
    "print(\"\\nüîç PRZYK≈ÅADOWE DANE:\")\n",
    "print(df.head())\n",
    "\n",
    "# Przygotowanie danych do modelu\n",
    "print(\"\\nüîß Przygotowanie danych do trenowania...\")\n",
    "\n",
    "# Funkcja do konwersji czasu na sekundy\n",
    "def time_to_seconds(time_str):\n",
    "    try:\n",
    "        if pd.isna(time_str) or time_str == '':\n",
    "            return None\n",
    "        time_str = str(time_str).strip()\n",
    "        parts = time_str.split(':')\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            return int(parts[0]) * 60 + int(parts[1])\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Funkcja do konwersji tempa (MM:SS/km) na sekundy/km\n",
    "def pace_to_seconds(pace_str):\n",
    "    try:\n",
    "        if pd.isna(pace_str) or pace_str == '':\n",
    "            return None\n",
    "        pace_str = str(pace_str).strip()\n",
    "        if '.' in pace_str:  # Liczba dziesiƒôtna (minuty)\n",
    "            return float(pace_str) * 60\n",
    "        else:  # Format MM:SS\n",
    "            parts = pace_str.split(':')\n",
    "            if len(parts) == 2:\n",
    "                return int(parts[0]) * 60 + int(parts[1])\n",
    "            else:\n",
    "                return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Konwersja danych\n",
    "df['sex_numeric'] = df['P≈Çeƒá'].map({'M': 1, 'K': 0, 'M ': 1, 'K ': 0})\n",
    "df['Rocznik_num'] = pd.to_numeric(df['Rocznik'], errors='coerce')\n",
    "df['half_marathon_seconds'] = df['Czas'].apply(time_to_seconds)\n",
    "df['pace_5km_seconds'] = df['5 km Tempo'].apply(pace_to_seconds)\n",
    "\n",
    "# Oblicz wiek\n",
    "df['age'] = df['Year'] - df['Rocznik_num']\n",
    "\n",
    "print(f\"\\nüìä Dane po przetworzeniu:\")\n",
    "print(f\"Przyk≈Çadowe wiersze:\")\n",
    "sample_data = df[['P≈Çeƒá', 'sex_numeric', 'Rocznik', 'age', '5 km Tempo', 'pace_5km_seconds', 'Czas', 'half_marathon_seconds']].head(10)\n",
    "print(sample_data)\n",
    "\n",
    "# Statystyki\n",
    "print(f\"\\nüìà STATYSTYKI:\")\n",
    "print(f\"Liczba rekord√≥w: {len(df)}\")\n",
    "print(f\"P≈Çeƒá M/K: {df['sex_numeric'].value_counts().to_dict()}\")\n",
    "print(f\"Wiek - min: {df['age'].min()}, max: {df['age'].max()}\")\n",
    "print(f\"Czas p√≥≈Çmaratonu - min: {df['half_marathon_seconds'].min()/60:.1f}min, max: {df['half_marathon_seconds'].max()/60:.1f}min\")\n",
    "\n",
    "# Przygotowanie cech i targetu\n",
    "features = df[['sex_numeric', 'age', 'pace_5km_seconds']].dropna()\n",
    "target = df.loc[features.index, 'half_marathon_seconds']\n",
    "\n",
    "# Usu≈Ñ rekordy gdzie target jest None\n",
    "valid_idx = target.notna()\n",
    "features = features[valid_idx]\n",
    "target = target[valid_idx]\n",
    "\n",
    "print(f\"\\nüìä Dane do trenowania:\")\n",
    "print(f\"Cechy: {features.shape}\")\n",
    "print(f\"Target: {target.shape}\")\n",
    "\n",
    "if len(features) > 100:\n",
    "    # Podzia≈Ç na train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    \n",
    "    # Trenowanie modelu\n",
    "    print(\"\\nü§ñ Trenowanie modelu...\")\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Ewaluacja\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nüìä Wyniki modelu:\")\n",
    "    print(f\"MAE: {mae:.2f} sekund ({mae/60:.1f} minut)\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f} sekund\")\n",
    "    \n",
    "    # Przyk≈Çadowe predykcje\n",
    "    print(f\"\\nüîç Przyk≈Çadowe predykcje:\")\n",
    "    for i in range(5):\n",
    "        actual_min = y_test.iloc[i] / 60\n",
    "        pred_min = y_pred[i] / 60\n",
    "        diff = pred_min - actual_min\n",
    "        print(f\"  Rzeczywiste: {actual_min:.1f}min, Przewidziane: {pred_min:.1f}min (r√≥≈ºnica: {diff:+.1f}min)\")\n",
    "    \n",
    "    # Zapis modelu\n",
    "    print(\"\\nüíæ Zapis modelu...\")\n",
    "    model_bytes = io.BytesIO()\n",
    "    joblib.dump(model, model_bytes)\n",
    "    model_bytes.seek(0)\n",
    "    \n",
    "    s3.upload_fileobj(model_bytes, \n",
    "                      os.getenv('DO_SPACES_BUCKET'), \n",
    "                      'trained_model.pkl')\n",
    "    \n",
    "    print(\"‚úÖ Model zapisany w DO Spaces jako 'trained_model.pkl'!\")\n",
    "    \n",
    "    # Wa≈ºno≈õƒá cech\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': ['P≈Çeƒá', 'Wiek', 'Tempo_5km'],\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ Wa≈ºno≈õƒá cech:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Za ma≈Ço danych do trenowania!\")\n",
    "\n",
    "print(\"\\nüéâ Pipeline zako≈Ñczony!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faba109e-0ffa-44a9-bbd5-9cd57f3911c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Debugowanie struktury danych...\n",
      "\n",
      "üîç DEBUG 2023:\n",
      "PIERWSZY WIERSZ (nag≈Ç√≥wki):\n",
      "  Kolumna 0: '1.0'\n",
      "  Kolumna 1: '1787'\n",
      "  Kolumna 2: 'TOMASZ'\n",
      "  Kolumna 3: 'GRYCKO'\n",
      "  Kolumna 4: ''\n",
      "  Kolumna 5: 'POL'\n",
      "  Kolumna 6: 'UKS BLIZA W≈ÅADYS≈ÅAWOWO'\n",
      "  Kolumna 7: 'M'\n",
      "  Kolumna 8: '1'\n",
      "  Kolumna 9: 'M30'\n",
      "  Kolumna 10: '1'\n",
      "  Kolumna 11: '1992.0'\n",
      "  Kolumna 12: '00:14:37'\n",
      "  Kolumna 13: '1.0'\n",
      "  Kolumna 14: '2.9233333333333333'\n",
      "  Kolumna 15: '00:29:15'\n",
      "  Kolumna 16: '1.0'\n",
      "  Kolumna 17: '2.9266666666666667'\n",
      "  Kolumna 18: '00:44:47'\n",
      "  Kolumna 19: '1.0'\n",
      "  Kolumna 20: '3.106666666666667'\n",
      "  Kolumna 21: '01:01:43'\n",
      "  Kolumna 22: '1.0'\n",
      "  Kolumna 23: '3.3866666666666663'\n",
      "  Kolumna 24: '0.031399999999999956'\n",
      "  Kolumna 25: '01:04:59'\n",
      "  Kolumna 26: '3.0805088093545074'\n",
      "\n",
      "DRUGI WIERSZ (przyk≈Çadowe dane):\n",
      "  Kolumna 0: '2.0'\n",
      "  Kolumna 1: '3'\n",
      "  Kolumna 2: 'ARKADIUSZ'\n",
      "  Kolumna 3: 'GARDZIELEWSKI'\n",
      "  Kolumna 4: 'WROC≈ÅAW'\n",
      "  Kolumna 5: 'POL'\n",
      "  Kolumna 6: 'ARKADIUSZGARDZIELEWSKI.PL'\n",
      "  Kolumna 7: 'M'\n",
      "  Kolumna 8: '2'\n",
      "  Kolumna 9: 'M30'\n",
      "  Kolumna 10: '2'\n",
      "  Kolumna 11: '1986.0'\n",
      "  Kolumna 12: '00:14:48'\n",
      "  Kolumna 13: '2.0'\n",
      "  Kolumna 14: '2.96'\n",
      "  Kolumna 15: '00:29:43'\n",
      "  Kolumna 16: '2.0'\n",
      "  Kolumna 17: '2.9833333333333334'\n",
      "  Kolumna 18: '00:45:26'\n",
      "  Kolumna 19: '2.0'\n",
      "  Kolumna 20: '3.143333333333333'\n",
      "  Kolumna 21: '01:03:08'\n",
      "  Kolumna 22: '2.0'\n",
      "  Kolumna 23: '3.54'\n",
      "  Kolumna 24: '0.03800000000000006'\n",
      "  Kolumna 25: '01:06:23'\n",
      "  Kolumna 26: '3.1468752468989494'\n",
      "\n",
      "üîç DEBUG 2024:\n",
      "PIERWSZY WIERSZ (nag≈Ç√≥wki):\n",
      "  Kolumna 0: '1.0'\n",
      "  Kolumna 1: '596'\n",
      "  Kolumna 2: 'NIKODEM'\n",
      "  Kolumna 3: 'DWORCZAK'\n",
      "  Kolumna 4: 'KO≈öCIAN'\n",
      "  Kolumna 5: 'POL'\n",
      "  Kolumna 6: ''\n",
      "  Kolumna 7: 'M'\n",
      "  Kolumna 8: '1'\n",
      "  Kolumna 9: 'M20'\n",
      "  Kolumna 10: '1'\n",
      "  Kolumna 11: '1998.0'\n",
      "  Kolumna 12: '00:15:06'\n",
      "  Kolumna 13: '3.0'\n",
      "  Kolumna 14: '3.02'\n",
      "  Kolumna 15: '00:29:42'\n",
      "  Kolumna 16: '3.0'\n",
      "  Kolumna 17: '2.92'\n",
      "  Kolumna 18: '00:45:07'\n",
      "  Kolumna 19: '2.0'\n",
      "  Kolumna 20: '3.0833333333333335'\n",
      "  Kolumna 21: '01:00:33'\n",
      "  Kolumna 22: '1.0'\n",
      "  Kolumna 23: '3.0866666666666664'\n",
      "  Kolumna 24: '0.007266666666666816'\n",
      "  Kolumna 25: '01:04:03'\n",
      "  Kolumna 26: '3.036264517658213'\n",
      "\n",
      "DRUGI WIERSZ (przyk≈Çadowe dane):\n",
      "  Kolumna 0: '2.0'\n",
      "  Kolumna 1: '616'\n",
      "  Kolumna 2: 'MATEUSZ'\n",
      "  Kolumna 3: 'KACZOR'\n",
      "  Kolumna 4: 'RADOM'\n",
      "  Kolumna 5: 'POL'\n",
      "  Kolumna 6: 'RLTL OPTIMA RADOM'\n",
      "  Kolumna 7: 'M'\n",
      "  Kolumna 8: '2'\n",
      "  Kolumna 9: 'M20'\n",
      "  Kolumna 10: '2'\n",
      "  Kolumna 11: '1997.0'\n",
      "  Kolumna 12: '00:15:06'\n",
      "  Kolumna 13: '4.0'\n",
      "  Kolumna 14: '3.02'\n",
      "  Kolumna 15: '00:29:42'\n",
      "  Kolumna 16: '1.0'\n",
      "  Kolumna 17: '2.92'\n",
      "  Kolumna 18: '00:45:07'\n",
      "  Kolumna 19: '3.0'\n",
      "  Kolumna 20: '3.0833333333333335'\n",
      "  Kolumna 21: '01:00:38'\n",
      "  Kolumna 22: '2.0'\n",
      "  Kolumna 23: '3.103333333333333'\n",
      "  Kolumna 24: '0.008266666666666768'\n",
      "  Kolumna 25: '01:04:24'\n",
      "  Kolumna 26: '3.0528561270443233'\n",
      "\n",
      "üéØ SZUKAM KOLUMN Z DANymi:\n",
      "\n",
      "--- 2023 ---\n",
      "Kolumna 0: '2.0'\n",
      "Kolumna 1: '3'\n",
      "Kolumna 2: 'ARKADIUSZ'\n",
      "Kolumna 3: 'GARDZIELEWSKI'\n",
      "Kolumna 4: 'WROC≈ÅAW'\n",
      "Kolumna 5: 'POL'\n",
      "Kolumna 6: 'ARKADIUSZGARDZIELEWSKI.PL'\n",
      "Kolumna 7: 'M'\n",
      "Kolumna 8: '2'\n",
      "Kolumna 9: 'M30'\n",
      "\n",
      "--- 2024 ---\n",
      "Kolumna 0: '2.0'\n",
      "Kolumna 1: '616'\n",
      "Kolumna 2: 'MATEUSZ'\n",
      "Kolumna 3: 'KACZOR'\n",
      "Kolumna 4: 'RADOM'\n",
      "Kolumna 5: 'POL'\n",
      "Kolumna 6: 'RLTL OPTIMA RADOM'\n",
      "Kolumna 7: 'M'\n",
      "Kolumna 8: '2'\n",
      "Kolumna 9: 'M20'\n"
     ]
    }
   ],
   "source": [
    "# training_pipeline_debug_columns.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Za≈Çaduj zmienne ≈õrodowiskowe\n",
    "load_dotenv()\n",
    "\n",
    "# Po≈ÇƒÖczenie z DigitalOcean Spaces\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client('s3',\n",
    "                   region_name=os.getenv('DO_SPACES_REGION'),\n",
    "                   endpoint_url=os.getenv('DO_SPACES_ENDPOINT'),\n",
    "                   aws_access_key_id=os.getenv('DO_SPACES_KEY'),\n",
    "                   aws_secret_access_key=os.getenv('DO_SPACES_SECRET'))\n",
    "\n",
    "def debug_columns(filename, year):\n",
    "    print(f\"\\nüîç DEBUG {year}:\")\n",
    "    response = s3.get_object(Bucket=os.getenv('DO_SPACES_BUCKET'), Key=filename)\n",
    "    df_temp = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "    \n",
    "    # Rozdziel kolumny wed≈Çug ≈õrednika\n",
    "    df_split = df_temp.iloc[:, 0].str.split(';', expand=True)\n",
    "    \n",
    "    # Poka≈º pierwsze 2 wiersze z numerami kolumn\n",
    "    print(\"PIERWSZY WIERSZ (nag≈Ç√≥wki):\")\n",
    "    for i, col in enumerate(df_split.iloc[0]):\n",
    "        print(f\"  Kolumna {i}: '{col}'\")\n",
    "    \n",
    "    print(\"\\nDRUGI WIERSZ (przyk≈Çadowe dane):\")\n",
    "    for i, col in enumerate(df_split.iloc[1]):\n",
    "        print(f\"  Kolumna {i}: '{col}'\")\n",
    "    \n",
    "    return df_split\n",
    "\n",
    "print(\"üì• Debugowanie struktury danych...\")\n",
    "df_2023_debug = debug_columns('halfmarathon_wroclaw_2023__final.csv', 2023)\n",
    "df_2024_debug = debug_columns('halfmarathon_wroclaw_2024__final.csv', 2024)\n",
    "\n",
    "# Sprawd≈∫my kt√≥re kolumny zawierajƒÖ kluczowe informacje\n",
    "print(\"\\nüéØ SZUKAM KOLUMN Z DANymi:\")\n",
    "keywords = {\n",
    "    'p≈Çeƒá': ['M', 'K'],\n",
    "    'wiek': ['1990', '1995', '2000'], \n",
    "    'czas_5km': ['00:15:', '00:20:'],\n",
    "    'czas_p√≥≈Çmaraton': ['01:10:', '01:30:']\n",
    "}\n",
    "\n",
    "for year, df_debug in [('2023', df_2023_debug), ('2024', df_2024_debug)]:\n",
    "    print(f\"\\n--- {year} ---\")\n",
    "    for i in range(min(10, len(df_debug.columns))):  # Sprawd≈∫ pierwsze 10 kolumn\n",
    "        col_data = df_debug[i].iloc[1]  # Drugi wiersz (pierwsze dane)\n",
    "        print(f\"Kolumna {i}: '{col_data}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47277389-bcbd-44ea-a1c9-e4a4a27b8b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Przetwarzanie danych 2023...\n",
      "üì• Przetwarzanie danych 2024...\n",
      "\n",
      "üìä Po≈ÇƒÖczone dane: (21955, 5)\n",
      "\n",
      "üîç PRZYK≈ÅADOWE DANE:\n",
      "  P≈Çeƒá Rocznik  5km_czas Czas_p√≥≈Çmaraton  Year\n",
      "0    M  1986.0  00:14:48        01:06:23  2023\n",
      "1    M  1996.0  00:15:46        01:08:24  2023\n",
      "2    M  1988.0  00:16:11        01:10:16  2023\n",
      "3    M  1995.0  00:16:12        01:10:27  2023\n",
      "4    M  1983.0  00:16:09        01:10:34  2023\n",
      "\n",
      "üîß Przygotowanie danych do trenowania...\n",
      "\n",
      "üìä Dane po przetworzeniu:\n",
      "  P≈Çeƒá  sex_numeric Rocznik   age  5km_czas  time_5km_seconds  \\\n",
      "0    M          1.0  1986.0  37.0  00:14:48             888.0   \n",
      "1    M          1.0  1996.0  27.0  00:15:46             946.0   \n",
      "2    M          1.0  1988.0  35.0  00:16:11             971.0   \n",
      "3    M          1.0  1995.0  28.0  00:16:12             972.0   \n",
      "4    M          1.0  1983.0  40.0  00:16:09             969.0   \n",
      "5    M          1.0  1999.0  24.0  00:15:37             937.0   \n",
      "6    M          1.0  1989.0  34.0  00:16:30             990.0   \n",
      "7    M          1.0  2001.0  22.0  00:17:10            1030.0   \n",
      "8    M          1.0  1992.0  31.0  00:16:53            1013.0   \n",
      "9    M          1.0  1997.0  26.0  00:17:09            1029.0   \n",
      "\n",
      "   pace_5km_seconds_per_km Czas_p√≥≈Çmaraton  half_marathon_seconds  \n",
      "0                    177.6        01:06:23                 3983.0  \n",
      "1                    189.2        01:08:24                 4104.0  \n",
      "2                    194.2        01:10:16                 4216.0  \n",
      "3                    194.4        01:10:27                 4227.0  \n",
      "4                    193.8        01:10:34                 4234.0  \n",
      "5                    187.4        01:11:18                 4278.0  \n",
      "6                    198.0        01:11:42                 4302.0  \n",
      "7                    206.0        01:14:16                 4456.0  \n",
      "8                    202.6        01:14:22                 4462.0  \n",
      "9                    205.8        01:14:43                 4483.0  \n",
      "\n",
      "üìà STATYSTYKI:\n",
      "Liczba rekord√≥w: 21955\n",
      "P≈Çeƒá - M: 15337, K: 6607\n",
      "Wiek - min: 17, max: 2024, ≈õrednia: 42.1\n",
      "Czas p√≥≈Çmaratonu - min: 64.4min, max: 212.6min\n",
      "\n",
      "üìä Dane do trenowania:\n",
      "Cechy: (17925, 3)\n",
      "Target: (17925,)\n",
      "Train: (14340, 3), Test: (3585, 3)\n",
      "\n",
      "ü§ñ Trenowanie modelu...\n",
      "\n",
      "üìä Wyniki modelu:\n",
      "MAE: 338.31 sekund (5.6 minut)\n",
      "RMSE: 465.73 sekund (7.8 minut)\n",
      "\n",
      "üîç Przyk≈Çadowe predykcje (test set):\n",
      "  Rzeczywiste: 110.0min, Przewidziane: 109.8min (r√≥≈ºnica: -0.1min)\n",
      "  Rzeczywiste: 147.8min, Przewidziane: 148.5min (r√≥≈ºnica: +0.6min)\n",
      "  Rzeczywiste: 126.1min, Przewidziane: 128.8min (r√≥≈ºnica: +2.7min)\n",
      "  Rzeczywiste: 124.8min, Przewidziane: 138.7min (r√≥≈ºnica: +13.9min)\n",
      "  Rzeczywiste: 143.4min, Przewidziane: 135.7min (r√≥≈ºnica: -7.7min)\n",
      "\n",
      "üíæ Zapis modelu...\n",
      "‚úÖ Model zapisany w DO Spaces jako 'trained_model.pkl'!\n",
      "\n",
      "üéØ Wa≈ºno≈õƒá cech:\n",
      "     feature  importance\n",
      "2  Tempo_5km    0.942636\n",
      "1       Wiek    0.050107\n",
      "0       P≈Çeƒá    0.007258\n",
      "\n",
      "üéâ Pipeline zako≈Ñczony pomy≈õlnie!\n",
      "Model wytrenowany na 17925 rekordach\n",
      "≈öredni b≈ÇƒÖd: 5.6 minut\n",
      "\n",
      "==================================================\n",
      "üéØ MODEL GOTOWY DO U≈ªYCIA W APLIKACJI!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# training_pipeline_final.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Za≈Çaduj zmienne ≈õrodowiskowe\n",
    "load_dotenv()\n",
    "\n",
    "# Po≈ÇƒÖczenie z DigitalOcean Spaces\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client('s3',\n",
    "                   region_name=os.getenv('DO_SPACES_REGION'),\n",
    "                   endpoint_url=os.getenv('DO_SPACES_ENDPOINT'),\n",
    "                   aws_access_key_id=os.getenv('DO_SPACES_KEY'),\n",
    "                   aws_secret_access_key=os.getenv('DO_SPACES_SECRET'))\n",
    "\n",
    "def process_year_data(filename, year):\n",
    "    response = s3.get_object(Bucket=os.getenv('DO_SPACES_BUCKET'), Key=filename)\n",
    "    df_temp = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "    \n",
    "    # Rozdziel kolumny wed≈Çug ≈õrednika\n",
    "    df_split = df_temp.iloc[:, 0].str.split(';', expand=True)\n",
    "    \n",
    "    # Mapowanie kolumn na podstawie debugu\n",
    "    column_mapping = {\n",
    "        'P≈Çeƒá': 7,           # Kolumna z p≈ÇciƒÖ (M/K)\n",
    "        'Rocznik': 11,       # Kolumna z rocznikiem\n",
    "        '5km_czas': 12,      # Kolumna z czasem na 5km\n",
    "        'Czas_p√≥≈Çmaraton': 25 # Kolumna z czasem p√≥≈Çmaratonu\n",
    "    }\n",
    "    \n",
    "    # Wybierz tylko potrzebne kolumny\n",
    "    selected_data = pd.DataFrame()\n",
    "    for col_name, col_idx in column_mapping.items():\n",
    "        selected_data[col_name] = df_split[col_idx]\n",
    "    \n",
    "    # Usu≈Ñ pierwszy wiersz (nag≈Ç√≥wki)\n",
    "    selected_data = selected_data.iloc[1:]\n",
    "    selected_data['Year'] = year\n",
    "    \n",
    "    return selected_data\n",
    "\n",
    "print(\"üì• Przetwarzanie danych 2023...\")\n",
    "df_2023 = process_year_data('halfmarathon_wroclaw_2023__final.csv', 2023)\n",
    "\n",
    "print(\"üì• Przetwarzanie danych 2024...\")\n",
    "df_2024 = process_year_data('halfmarathon_wroclaw_2024__final.csv', 2024)\n",
    "\n",
    "# Po≈ÇƒÖcz dane\n",
    "df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "print(f\"\\nüìä Po≈ÇƒÖczone dane: {df.shape}\")\n",
    "\n",
    "print(\"\\nüîç PRZYK≈ÅADOWE DANE:\")\n",
    "print(df.head())\n",
    "\n",
    "# Przygotowanie danych do modelu\n",
    "print(\"\\nüîß Przygotowanie danych do trenowania...\")\n",
    "\n",
    "# Funkcja do konwersji czasu HH:MM:SS na sekundy\n",
    "def time_to_seconds(time_str):\n",
    "    try:\n",
    "        if pd.isna(time_str) or time_str == '':\n",
    "            return None\n",
    "        time_str = str(time_str).strip()\n",
    "        parts = time_str.split(':')\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            return int(parts[0]) * 60 + int(parts[1])\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Konwersja danych\n",
    "df['sex_numeric'] = df['P≈Çeƒá'].map({'M': 1, 'K': 0})\n",
    "df['Rocznik_num'] = pd.to_numeric(df['Rocznik'], errors='coerce')\n",
    "df['half_marathon_seconds'] = df['Czas_p√≥≈Çmaraton'].apply(time_to_seconds)\n",
    "df['time_5km_seconds'] = df['5km_czas'].apply(time_to_seconds)\n",
    "\n",
    "# Oblicz tempo na km z czasu 5km (sekundy/km)\n",
    "df['pace_5km_seconds_per_km'] = df['time_5km_seconds'] / 5.0\n",
    "\n",
    "# Oblicz wiek\n",
    "df['age'] = df['Year'] - df['Rocznik_num']\n",
    "\n",
    "print(f\"\\nüìä Dane po przetworzeniu:\")\n",
    "sample_cols = ['P≈Çeƒá', 'sex_numeric', 'Rocznik', 'age', '5km_czas', 'time_5km_seconds', 'pace_5km_seconds_per_km', 'Czas_p√≥≈Çmaraton', 'half_marathon_seconds']\n",
    "print(df[sample_cols].head(10))\n",
    "\n",
    "# Statystyki\n",
    "print(f\"\\nüìà STATYSTYKI:\")\n",
    "print(f\"Liczba rekord√≥w: {len(df)}\")\n",
    "print(f\"P≈Çeƒá - M: {(df['sex_numeric'] == 1).sum()}, K: {(df['sex_numeric'] == 0).sum()}\")\n",
    "print(f\"Wiek - min: {df['age'].min():.0f}, max: {df['age'].max():.0f}, ≈õrednia: {df['age'].mean():.1f}\")\n",
    "print(f\"Czas p√≥≈Çmaratonu - min: {df['half_marathon_seconds'].min()/60:.1f}min, max: {df['half_marathon_seconds'].max()/60:.1f}min\")\n",
    "\n",
    "# Przygotowanie cech i targetu\n",
    "features = df[['sex_numeric', 'age', 'pace_5km_seconds_per_km']].copy()\n",
    "target = df['half_marathon_seconds'].copy()\n",
    "\n",
    "# Usu≈Ñ brakujƒÖce warto≈õci\n",
    "mask = features.notna().all(axis=1) & target.notna()\n",
    "features = features[mask]\n",
    "target = target[mask]\n",
    "\n",
    "print(f\"\\nüìä Dane do trenowania:\")\n",
    "print(f\"Cechy: {features.shape}\")\n",
    "print(f\"Target: {target.shape}\")\n",
    "\n",
    "if len(features) > 100:\n",
    "    # Podzia≈Ç na train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    \n",
    "    # Trenowanie modelu\n",
    "    print(\"\\nü§ñ Trenowanie modelu...\")\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Ewaluacja\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"\\nüìä Wyniki modelu:\")\n",
    "    print(f\"MAE: {mae:.2f} sekund ({mae/60:.1f} minut)\")\n",
    "    print(f\"RMSE: {rmse:.2f} sekund ({rmse/60:.1f} minut)\")\n",
    "    \n",
    "    # Przyk≈Çadowe predykcje\n",
    "    print(f\"\\nüîç Przyk≈Çadowe predykcje (test set):\")\n",
    "    for i in range(5):\n",
    "        actual_min = y_test.iloc[i] / 60\n",
    "        pred_min = y_pred[i] / 60\n",
    "        diff = pred_min - actual_min\n",
    "        print(f\"  Rzeczywiste: {actual_min:.1f}min, Przewidziane: {pred_min:.1f}min (r√≥≈ºnica: {diff:+.1f}min)\")\n",
    "    \n",
    "    # Zapis modelu\n",
    "    print(\"\\nüíæ Zapis modelu...\")\n",
    "    model_bytes = io.BytesIO()\n",
    "    joblib.dump(model, model_bytes)\n",
    "    model_bytes.seek(0)\n",
    "    \n",
    "    s3.upload_fileobj(model_bytes, \n",
    "                      os.getenv('DO_SPACES_BUCKET'), \n",
    "                      'trained_model.pkl')\n",
    "    \n",
    "    print(\"‚úÖ Model zapisany w DO Spaces jako 'trained_model.pkl'!\")\n",
    "    \n",
    "    # Wa≈ºno≈õƒá cech\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': ['P≈Çeƒá', 'Wiek', 'Tempo_5km'],\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ Wa≈ºno≈õƒá cech:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    print(f\"\\nüéâ Pipeline zako≈Ñczony pomy≈õlnie!\")\n",
    "    print(f\"Model wytrenowany na {len(features)} rekordach\")\n",
    "    print(f\"≈öredni b≈ÇƒÖd: {mae/60:.1f} minut\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Za ma≈Ço danych do trenowania!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéØ MODEL GOTOWY DO U≈ªYCIA W APLIKACJI!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763f34f-c8fe-49f4-9d0a-4634acc11a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (od_zera_do_ai)",
   "language": "python",
   "name": "od_zera_do_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
